{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5fe9feb6-2b35-414a-be9d-771eabdbb0dc",
      "metadata": {
        "id": "5fe9feb6-2b35-414a-be9d-771eabdbb0dc"
      },
      "source": [
        "## EZKL GCN Notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "nGcl_1sltpRq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGcl_1sltpRq",
        "outputId": "642693ac-970f-4ad9-80f5-e58c69f04ee9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torch-scatter\n",
            "  Downloading torch_scatter-2.1.1.tar.gz (107 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.6/107.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch-sparse\n",
            "  Downloading torch_sparse-0.6.17.tar.gz (209 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.3.1.tar.gz (661 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.6/661.6 kB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.11.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.23.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2023.7.22)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.2.0)\n",
            "Building wheels for collected packages: torch-scatter, torch-sparse, torch-geometric\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-scatter: filename=torch_scatter-2.1.1-cp310-cp310-linux_x86_64.whl size=491866 sha256=b03969f64190837045a0beee5b7447f1b3ff0964336d59e1c973e92ff747d8e7\n",
            "  Stored in directory: /root/.cache/pip/wheels/ef/67/58/6566a3b61c6ec0f2ca0c2c324cd035ef2955601f0fb3197d5f\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-sparse: filename=torch_sparse-0.6.17-cp310-cp310-linux_x86_64.whl size=1053726 sha256=61b20ed01dfff2ee251bc3dcef668d221d388239b80fa8b8427caa0887377830\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/25/e7/037b58fa47ba781444fd101a2f06c63a9d4e967ca6b910c53a\n",
            "  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.3.1-py3-none-any.whl size=910454 sha256=db01d82f560cb847c2e3949688413ca60561370d22ded3abc81b599f5028a549\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/dc/30/e2874821ff308ee67dcd7a66dbde912411e19e35a1addda028\n",
            "Successfully built torch-scatter torch-sparse torch-geometric\n",
            "Installing collected packages: torch-scatter, torch-sparse, torch-geometric\n",
            "Successfully installed torch-geometric-2.3.1 torch-scatter-2.1.1 torch-sparse-0.6.17\n"
          ]
        }
      ],
      "source": [
        "!pip install torch-scatter torch-sparse torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "1005303a-cd48-4766-9c43-2116f94ed381",
      "metadata": {
        "id": "1005303a-cd48-4766-9c43-2116f94ed381"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# check if notebook is in colab\n",
        "try:\n",
        "    # install ezkl\n",
        "    import google.colab\n",
        "    import subprocess\n",
        "    import sys\n",
        "    for e in [\"ezkl\", \"onnx\", \"torch\", \"torchvision\", \"torch-scatter\", \"torch-sparse\", \"torch-geometric\"]:\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", e])\n",
        "\n",
        "# rely on local installation of ezkl if the notebook is not in colab\n",
        "except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "89e5732e-a97b-445e-9174-69689e37e72c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89e5732e-a97b-445e-9174-69689e37e72c",
        "outputId": "24049b0a-439b-4327-a829-4b4045490f0f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Data(x=[3, 1], edge_index=[2, 3])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "edge_index = torch.tensor([[2, 1, 3],\n",
        "                           [0, 0, 2]], dtype=torch.long)\n",
        "x = torch.tensor([[1], [1], [1]], dtype=torch.float)\n",
        "\n",
        "data = Data(x=x, edge_index=edge_index)\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "73b34e81-63cb-44b0-9f95-f8490e844676",
      "metadata": {
        "id": "73b34e81-63cb-44b0-9f95-f8490e844676"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import math\n",
        "from torch_geometric.nn import MessagePassing\n",
        "from torch.nn.modules.module import Module\n",
        "\n",
        "def glorot(tensor):\n",
        "    if tensor is not None:\n",
        "        stdv = math.sqrt(6.0 / (tensor.size(-2) + tensor.size(-1)))\n",
        "        tensor.data.uniform_(-stdv, stdv)\n",
        "\n",
        "\n",
        "def zeros(tensor):\n",
        "    if tensor is not None:\n",
        "        tensor.data.fill_(0)\n",
        "\n",
        "class GCNConv(Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(GCNConv, self).__init__()  # \"Add\" aggregation.\n",
        "        self.lin = torch.nn.Linear(in_channels, out_channels)\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        glorot(self.lin.weight)\n",
        "        zeros(self.lin.bias)\n",
        "\n",
        "    def forward(self, x, adj_t, deg):\n",
        "        x = self.lin(x)\n",
        "        adj_t = self.normalize_adj(adj_t, deg)\n",
        "        x = adj_t @ x\n",
        "\n",
        "        return x\n",
        "\n",
        "    def normalize_adj(self, adj_t, deg):\n",
        "        deg.masked_fill_(deg == 0, 1.)\n",
        "        deg_inv_sqrt = deg.pow_(-0.5)\n",
        "        deg_inv_sqrt.masked_fill_(deg_inv_sqrt == 1, 0.)\n",
        "        adj_t = adj_t *  deg_inv_sqrt.view(-1, 1) # N, 1\n",
        "        adj_t = adj_t *  deg_inv_sqrt.view(1, -1) # 1, N\n",
        "\n",
        "        return adj_t"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae70bc34-def7-40fd-9558-2500c6f29323",
      "metadata": {
        "id": "ae70bc34-def7-40fd-9558-2500c6f29323"
      },
      "source": [
        "## Train Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "7ca117a1-7473-42a6-be95-dc314eb3e251",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ca117a1-7473-42a6-be95-dc314eb3e251",
        "outputId": "edacee52-8a88-4c02-9a71-fd094e89c7b9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import os.path as osp\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.datasets import Planetoid\n",
        "import torch_geometric.transforms as T\n",
        "\n",
        "path = osp.join(os.getcwd(), 'data', 'Cora')\n",
        "dataset = Planetoid(path, 'Cora')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "807f4d87-6acc-4cbb-80e4-8eb09feb994c",
      "metadata": {
        "id": "807f4d87-6acc-4cbb-80e4-8eb09feb994c"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "from torch import tensor\n",
        "from torch.optim import Adam\n",
        "\n",
        "# define num feat to use for training here\n",
        "num_feat = 10\n",
        "\n",
        "def run(dataset, model, runs, epochs, lr, weight_decay, early_stopping):\n",
        "\n",
        "    val_losses, accs, durations = [], [], []\n",
        "    for _ in range(runs):\n",
        "        data = dataset[0]\n",
        "        data = data.to(device)\n",
        "\n",
        "        model.to(device).reset_parameters()\n",
        "        optimizer = Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.synchronize()\n",
        "\n",
        "        t_start = time.perf_counter()\n",
        "\n",
        "        best_val_loss = float('inf')\n",
        "        test_acc = 0\n",
        "        val_loss_history = []\n",
        "\n",
        "        for epoch in range(1, epochs + 1):\n",
        "            train(model, optimizer, data)\n",
        "            eval_info = evaluate(model, data)\n",
        "            eval_info['epoch'] = epoch\n",
        "\n",
        "            if eval_info['val_loss'] < best_val_loss:\n",
        "                best_val_loss = eval_info['val_loss']\n",
        "                test_acc = eval_info['test_acc']\n",
        "\n",
        "            val_loss_history.append(eval_info['val_loss'])\n",
        "            if early_stopping > 0 and epoch > epochs // 2:\n",
        "                tmp = tensor(val_loss_history[-(early_stopping + 1):-1])\n",
        "                if eval_info['val_loss'] > tmp.mean().item():\n",
        "                    break\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.synchronize()\n",
        "\n",
        "        t_end = time.perf_counter()\n",
        "\n",
        "        val_losses.append(best_val_loss)\n",
        "        accs.append(test_acc)\n",
        "        durations.append(t_end - t_start)\n",
        "\n",
        "    loss, acc, duration = tensor(val_losses), tensor(accs), tensor(durations)\n",
        "\n",
        "    print('Val Loss: {:.4f}, Test Accuracy: {:.3f} ± {:.3f}, Duration: {:.3f}'.\n",
        "          format(loss.mean().item(),\n",
        "                 acc.mean().item(),\n",
        "                 acc.std().item(),\n",
        "                 duration.mean().item()))\n",
        "\n",
        "\n",
        "def train(model, optimizer, data):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    E = data.edge_index.size(1)\n",
        "    N = data.x.size(0)\n",
        "    x = data.x[:, :num_feat]\n",
        "    adj_t = torch.sparse_coo_tensor(data.edge_index, torch.ones(E), size=(N, N)).to_dense().T\n",
        "    deg = torch.sum(adj_t, dim=1)\n",
        "    out = model(x, adj_t, deg)\n",
        "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "def evaluate(model, data):\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        E = data.edge_index.size(1)\n",
        "        N = data.x.size(0)\n",
        "        x = data.x[:, :num_feat]\n",
        "        adj_t = torch.sparse_coo_tensor(data.edge_index, torch.ones(E), size=(N, N)).to_dense().T\n",
        "        deg = torch.sum(adj_t, dim=1)\n",
        "        logits = model(x, adj_t, deg)\n",
        "\n",
        "    outs = {}\n",
        "    for key in ['train', 'val', 'test']:\n",
        "        mask = data['{}_mask'.format(key)]\n",
        "        loss = F.nll_loss(logits[mask], data.y[mask]).item()\n",
        "        pred = logits[mask].max(1)[1]\n",
        "        acc = pred.eq(data.y[mask]).sum().item() / mask.sum().item()\n",
        "\n",
        "        outs['{}_loss'.format(key)] = loss\n",
        "        outs['{}_acc'.format(key)] = acc\n",
        "\n",
        "    return outs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "28b3605e-e6fd-45ff-ae4b-607065f4849c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28b3605e-e6fd-45ff-ae4b-607065f4849c",
        "outputId": "b3ea504c-b57c-46d4-b382-aa54c9a4786f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1.5943, Test Accuracy: 0.350 ± 0.012, Duration: 25.914\n"
          ]
        }
      ],
      "source": [
        "runs = 10\n",
        "epochs = 200\n",
        "lr = 0.01\n",
        "weight_decay = 0.0005\n",
        "early_stopping = 10\n",
        "hidden = 16\n",
        "dropout = 0.5\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, dataset, num_feat):\n",
        "        super(Net, self).__init__()\n",
        "        # self.conv1 = GCNConv(dataset.num_features, hidden)\n",
        "        self.conv1 = GCNConv(num_feat, hidden)\n",
        "        self.conv2 = GCNConv(hidden, dataset.num_classes)\n",
        "\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.conv1.reset_parameters()\n",
        "        self.conv2.reset_parameters()\n",
        "\n",
        "    def forward(self, x, adj_t, deg):\n",
        "        x = F.relu(self.conv1(x, adj_t, deg))\n",
        "        x = F.dropout(x, p=dropout, training=self.training)\n",
        "        x = self.conv2(x, adj_t, deg)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "model = Net(dataset, num_feat)\n",
        "run(dataset, model, runs, epochs, lr, weight_decay, early_stopping)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cc3ffed-74c2-48e3-86bc-a5e51f44a09a",
      "metadata": {
        "id": "4cc3ffed-74c2-48e3-86bc-a5e51f44a09a"
      },
      "source": [
        "## EZKL Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "92585631-ff39-402e-bd1c-aaebdce682e5",
      "metadata": {
        "id": "92585631-ff39-402e-bd1c-aaebdce682e5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import ezkl\n",
        "\n",
        "\n",
        "model_path = os.path.join('network.onnx')\n",
        "compiled_model_path = os.path.join('network.compiled')\n",
        "pk_path = os.path.join('test.pk')\n",
        "vk_path = os.path.join('test.vk')\n",
        "settings_path = os.path.join('settings.json')\n",
        "srs_path = os.path.join('kzg.srs')\n",
        "witness_path = os.path.join('witness.json')\n",
        "data_path = os.path.join('input.json')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "d80d3169-cc70-4aee-bdc2-df9a435b3116",
      "metadata": {
        "id": "d80d3169-cc70-4aee-bdc2-df9a435b3116"
      },
      "outputs": [],
      "source": [
        "# Downsample graph\n",
        "num_node = 5\n",
        "\n",
        "# filter edges so that we only bring adjacencies among downsampled node\n",
        "filter_row = []\n",
        "filter_col = []\n",
        "row, col = dataset[0].edge_index\n",
        "for idx in range(row.size(0)):\n",
        "    if row[idx] < num_node and col[idx] < num_node:\n",
        "        filter_row.append(row[idx])\n",
        "        filter_col.append(col[idx])\n",
        "filter_edge_index = torch.stack([torch.tensor(filter_row), torch.tensor(filter_col)])\n",
        "num_edge = len(filter_row)\n",
        "\n",
        "\n",
        "x = dataset[0].x[:num_node, :num_feat]\n",
        "edge_index = filter_edge_index\n",
        "\n",
        "adj_t = torch.sparse_coo_tensor(edge_index, torch.ones(num_edge), size=(num_node, num_node)).to_dense().T\n",
        "deg = torch.sum(adj_t, dim=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "46367b2f-951d-403b-9346-e689de0bee3f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46367b2f-951d-403b-9346-e689de0bee3f",
        "outputId": "f063bf1b-e518-4fdb-b8ad-507c521acaa3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:619: UserWarning: ONNX Preprocess - Removing mutation from node aten::masked_fill_ on block input: 'deg.1'. This changes graph semantics. (Triggered internally at ../torch/csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:350.)\n",
            "  _C._jit_pass_onnx_remove_inplace_ops_for_onnx(graph, module)\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# Flips the neural net into inference mode\n",
        "model.eval()\n",
        "model.to('cpu')\n",
        "\n",
        "# No dynamic axis for GNN batch\n",
        "torch.onnx.export(model,               # model being run\n",
        "                      (x, adj_t, deg),               # model input (or a tuple for multiple inputs)\n",
        "                      model_path,            # where to save the model (can be a file or file-like object)\n",
        "                      export_params=True,        # store the trained parameter weights inside the model file\n",
        "                      opset_version=11,          # the ONNX version to export the model to\n",
        "                      do_constant_folding=True,  # whether to execute constant folding for optimization\n",
        "                      input_names = ['x', 'edge_index'],   # the model's input names\n",
        "                      output_names = ['output']) # the model's output names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "9e6da242-540e-48dc-bc20-d08fcd192af4",
      "metadata": {
        "id": "9e6da242-540e-48dc-bc20-d08fcd192af4"
      },
      "outputs": [],
      "source": [
        "torch_out = model(x, adj_t, deg)\n",
        "x_shape = x.shape\n",
        "adj_t_shape=adj_t.shape\n",
        "deg_shape=deg.shape\n",
        "\n",
        "x = ((x).detach().numpy()).reshape([-1]).tolist()\n",
        "adj_t = ((adj_t).detach().numpy()).reshape([-1]).tolist()\n",
        "deg = ((deg).detach().numpy()).reshape([-1]).tolist()\n",
        "\n",
        "data = dict(input_shapes=[x_shape, adj_t_shape, deg_shape],\n",
        "            input_data=[x, adj_t, deg],\n",
        "            output_data=[((torch_out).detach().numpy()).reshape([-1]).tolist()])\n",
        "json.dump(data, open(data_path, 'w'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "3393a884-7a14-435e-bb9e-4fa4fcbdc76b",
      "metadata": {
        "id": "3393a884-7a14-435e-bb9e-4fa4fcbdc76b",
        "tags": []
      },
      "outputs": [],
      "source": [
        "!RUST_LOG=trace\n",
        "import ezkl\n",
        "\n",
        "run_args = ezkl.PyRunArgs()\n",
        "run_args.input_scale = 5\n",
        "run_args.param_scale = 5\n",
        "# TODO: Dictionary outputs\n",
        "res = ezkl.gen_settings(model_path, settings_path, py_run_args=run_args)\n",
        "assert res == True\n",
        "\n",
        "res = await ezkl.calibrate_settings(data_path, model_path, settings_path, \"resources\")\n",
        "assert res == True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "8f86fceb",
      "metadata": {
        "id": "8f86fceb"
      },
      "outputs": [],
      "source": [
        "res = ezkl.compile_circuit(model_path, compiled_model_path, settings_path)\n",
        "assert res == True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "3b55c925",
      "metadata": {
        "id": "3b55c925"
      },
      "outputs": [],
      "source": [
        "# srs path\n",
        "res = ezkl.get_srs(srs_path, settings_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "d6478bab",
      "metadata": {
        "id": "d6478bab"
      },
      "outputs": [],
      "source": [
        "# now generate the witness file\n",
        "\n",
        "res = ezkl.gen_witness(data_path, compiled_model_path, witness_path)\n",
        "assert os.path.isfile(witness_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "b500c1ba",
      "metadata": {
        "id": "b500c1ba"
      },
      "outputs": [],
      "source": [
        "# HERE WE SETUP THE CIRCUIT PARAMS\n",
        "# WE GOT KEYS\n",
        "# WE GOT CIRCUIT PARAMETERS\n",
        "# EVERYTHING ANYONE HAS EVER NEEDED FOR ZK\n",
        "\n",
        "\n",
        "\n",
        "res = ezkl.setup(\n",
        "        compiled_model_path,\n",
        "        vk_path,\n",
        "        pk_path,\n",
        "        srs_path,\n",
        "    )\n",
        "\n",
        "assert res == True\n",
        "assert os.path.isfile(vk_path)\n",
        "assert os.path.isfile(pk_path)\n",
        "assert os.path.isfile(settings_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "ae152a64",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae152a64",
        "outputId": "599cc9b8-ee85-407e-f0da-b2360634d2a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'instances': [[[18394180685272187193, 2843742363274879387, 6495664164330342886, 3072557160466273026], [18394180685272187193, 2843742363274879387, 6495664164330342886, 3072557160466273026], [18394180685272187193, 2843742363274879387, 6495664164330342886, 3072557160466273026], [18394180685272187193, 2843742363274879387, 6495664164330342886, 3072557160466273026], [18394180685272187193, 2843742363274879387, 6495664164330342886, 3072557160466273026], [18394180685272187193, 2843742363274879387, 6495664164330342886, 3072557160466273026], [18394180685272187193, 2843742363274879387, 6495664164330342886, 3072557160466273026], [18394180685272187193, 2843742363274879387, 6495664164330342886, 3072557160466273026], [18394180685272187193, 2843742363274879387, 6495664164330342886, 3072557160466273026], [18394180685272187193, 2843742363274879387, 6495664164330342886, 3072557160466273026], [18394180685272187193, 2843742363274879387, 6495664164330342886, 3072557160466273026], [18394180685272187193, 2843742363274879387, 6495664164330342886, 3072557160466273026], [18394180685272187193, 2843742363274879387, 6495664164330342886, 3072557160466273026], [18394180685272187193, 2843742363274879387, 6495664164330342886, 3072557160466273026], [18394180685272187193, 2843742363274879387, 6495664164330342886, 3072557160466273026], [18394180685272187193, 2843742363274879387, 6495664164330342886, 3072557160466273026], [18394180685272187193, 2843742363274879387, 6495664164330342886, 3072557160466273026], [18394180685272187193, 2843742363274879387, 6495664164330342886, 3072557160466273026], [18394180685272187193, 2843742363274879387, 6495664164330342886, 3072557160466273026], [18394180685272187193, 2843742363274879387, 6495664164330342886, 3072557160466273026], [18394180685272187193, 2843742363274879387, 6495664164330342886, 3072557160466273026], [18394180685272187193, 2843742363274879387, 6495664164330342886, 3072557160466273026], [18394180685272187193, 2843742363274879387, 6495664164330342886, 3072557160466273026], [18394180685272187193, 2843742363274879387, 6495664164330342886, 3072557160466273026], [18394180685272187193, 2843742363274879387, 6495664164330342886, 3072557160466273026], [18394180685272187193, 2843742363274879387, 6495664164330342886, 3072557160466273026], [18394180685272187193, 2843742363274879387, 6495664164330342886, 3072557160466273026], [18394180685272187193, 2843742363274879387, 6495664164330342886, 3072557160466273026], [18394180685272187193, 2843742363274879387, 6495664164330342886, 3072557160466273026], [18394180685272187193, 2843742363274879387, 6495664164330342886, 3072557160466273026], [18394180685272187193, 2843742363274879387, 6495664164330342886, 3072557160466273026], [18394180685272187193, 2843742363274879387, 6495664164330342886, 3072557160466273026], [18394180685272187193, 2843742363274879387, 6495664164330342886, 3072557160466273026], [18394180685272187193, 2843742363274879387, 6495664164330342886, 3072557160466273026], [18394180685272187193, 2843742363274879387, 6495664164330342886, 3072557160466273026]]], 'proof': '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', 'transcript_type': 'EVM'}\n"
          ]
        }
      ],
      "source": [
        "# GENERATE A PROOF\n",
        "\n",
        "\n",
        "proof_path = os.path.join('test.pf')\n",
        "\n",
        "res = ezkl.prove(\n",
        "        witness_path,\n",
        "        compiled_model_path,\n",
        "        pk_path,\n",
        "        proof_path,\n",
        "        srs_path,\n",
        "        \"single\",\n",
        "    )\n",
        "\n",
        "print(res)\n",
        "assert os.path.isfile(proof_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "a2548b00",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2548b00",
        "outputId": "e2972113-c079-4cb2-bfc5-6f7ad2842195"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "verified\n"
          ]
        }
      ],
      "source": [
        "# VERIFY IT\n",
        "\n",
        "res = ezkl.verify(\n",
        "        proof_path,\n",
        "        settings_path,\n",
        "        vk_path,\n",
        "        srs_path,\n",
        "    )\n",
        "\n",
        "assert res == True\n",
        "print(\"verified\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.11.4 ('.env': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "af2b032f4d5a009ff33cd3ba5ac25dedfd7d71c9736fbe82aa90983ec2fc3628"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
