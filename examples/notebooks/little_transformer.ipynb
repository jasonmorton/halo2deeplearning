{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "d0a82619",
            "metadata": {},
            "source": [
                "Credits to [geohot](https://github.com/geohot/ai-notebooks/blob/master/mnist_gan.ipynb) for most of this code\n",
                "\n",
                "## Model Architecture and training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "12fb79a8",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Requirement already satisfied: pytorch_lightning in /Users/alexandercamuto/Documents/GitHub/ezkl/.env/lib/python3.9/site-packages (2.0.6)\n",
                        "Requirement already satisfied: torch>=1.11.0 in /Users/alexandercamuto/Documents/GitHub/ezkl/.env/lib/python3.9/site-packages (from pytorch_lightning) (2.0.1)\n",
                        "Requirement already satisfied: numpy>=1.17.2 in /Users/alexandercamuto/Documents/GitHub/ezkl/.env/lib/python3.9/site-packages (from pytorch_lightning) (1.23.0)\n",
                        "Requirement already satisfied: typing-extensions>=4.0.0 in /Users/alexandercamuto/Documents/GitHub/ezkl/.env/lib/python3.9/site-packages (from pytorch_lightning) (4.5.0)\n",
                        "Requirement already satisfied: packaging>=17.1 in /Users/alexandercamuto/Documents/GitHub/ezkl/.env/lib/python3.9/site-packages (from pytorch_lightning) (23.0)\n",
                        "Requirement already satisfied: fsspec[http]>2021.06.0 in /Users/alexandercamuto/Documents/GitHub/ezkl/.env/lib/python3.9/site-packages (from pytorch_lightning) (2023.6.0)\n",
                        "Requirement already satisfied: tqdm>=4.57.0 in /Users/alexandercamuto/Documents/GitHub/ezkl/.env/lib/python3.9/site-packages (from pytorch_lightning) (4.65.0)\n",
                        "Requirement already satisfied: torchmetrics>=0.7.0 in /Users/alexandercamuto/Documents/GitHub/ezkl/.env/lib/python3.9/site-packages (from pytorch_lightning) (1.0.3)\n",
                        "Requirement already satisfied: lightning-utilities>=0.7.0 in /Users/alexandercamuto/Documents/GitHub/ezkl/.env/lib/python3.9/site-packages (from pytorch_lightning) (0.9.0)\n",
                        "Requirement already satisfied: PyYAML>=5.4 in /Users/alexandercamuto/Documents/GitHub/ezkl/.env/lib/python3.9/site-packages (from pytorch_lightning) (6.0)\n",
                        "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Users/alexandercamuto/Documents/GitHub/ezkl/.env/lib/python3.9/site-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (3.8.4)\n",
                        "Requirement already satisfied: requests in /Users/alexandercamuto/Documents/GitHub/ezkl/.env/lib/python3.9/site-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (2.31.0)\n",
                        "Requirement already satisfied: sympy in /Users/alexandercamuto/Documents/GitHub/ezkl/.env/lib/python3.9/site-packages (from torch>=1.11.0->pytorch_lightning) (1.12)\n",
                        "Requirement already satisfied: networkx in /Users/alexandercamuto/Documents/GitHub/ezkl/.env/lib/python3.9/site-packages (from torch>=1.11.0->pytorch_lightning) (3.1)\n",
                        "Requirement already satisfied: jinja2 in /Users/alexandercamuto/Documents/GitHub/ezkl/.env/lib/python3.9/site-packages (from torch>=1.11.0->pytorch_lightning) (3.1.2)\n",
                        "Requirement already satisfied: filelock in /Users/alexandercamuto/Documents/GitHub/ezkl/.env/lib/python3.9/site-packages (from torch>=1.11.0->pytorch_lightning) (3.12.2)\n",
                        "Requirement already satisfied: attrs>=17.3.0 in /Users/alexandercamuto/Documents/GitHub/ezkl/.env/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (22.2.0)\n",
                        "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/alexandercamuto/Documents/GitHub/ezkl/.env/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (4.0.2)\n",
                        "Requirement already satisfied: aiosignal>=1.1.2 in /Users/alexandercamuto/Documents/GitHub/ezkl/.env/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.3.1)\n",
                        "Requirement already satisfied: frozenlist>=1.1.1 in /Users/alexandercamuto/Documents/GitHub/ezkl/.env/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.3.3)\n",
                        "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/alexandercamuto/Documents/GitHub/ezkl/.env/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.9.2)\n",
                        "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/alexandercamuto/Documents/GitHub/ezkl/.env/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (3.2.0)\n",
                        "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/alexandercamuto/Documents/GitHub/ezkl/.env/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (6.0.4)\n",
                        "Requirement already satisfied: MarkupSafe>=2.0 in /Users/alexandercamuto/Documents/GitHub/ezkl/.env/lib/python3.9/site-packages (from jinja2->torch>=1.11.0->pytorch_lightning) (2.1.3)\n",
                        "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/alexandercamuto/Documents/GitHub/ezkl/.env/lib/python3.9/site-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (1.26.16)\n",
                        "Requirement already satisfied: certifi>=2017.4.17 in /Users/alexandercamuto/Documents/GitHub/ezkl/.env/lib/python3.9/site-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (2023.5.7)\n",
                        "Requirement already satisfied: idna<4,>=2.5 in /Users/alexandercamuto/Documents/GitHub/ezkl/.env/lib/python3.9/site-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (3.4)\n",
                        "Requirement already satisfied: mpmath>=0.19 in /Users/alexandercamuto/Documents/GitHub/ezkl/.env/lib/python3.9/site-packages (from sympy->torch>=1.11.0->pytorch_lightning) (1.3.0)\n",
                        "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.2.1 is available.\n",
                        "You should consider upgrading via the '/Users/alexandercamuto/Documents/GitHub/ezkl/.env/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
                        "\u001b[0m"
                    ]
                }
            ],
            "source": [
                "!pip install pytorch_lightning\n",
                "\n",
                "import random\n",
                "import math\n",
                "import numpy as np\n",
                "\n",
                "import torch\n",
                "from torch import nn\n",
                "import torch.nn.functional as F\n",
                "\n",
                "import pytorch_lightning as pl"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "8638e94e",
            "metadata": {},
            "outputs": [],
            "source": [
                "class BaseDataModule(pl.LightningDataModule):\n",
                "  def __init__(self, batch_size=32, split=0.8, *args, **kwargs):\n",
                "    super().__init__()\n",
                "    self.ds_X, self.ds_Y = self.get_dataset(*args, **kwargs)\n",
                "    shuffler = np.random.permutation(self.ds_X.shape[0])\n",
                "    self.ds_X = self.ds_X[shuffler]\n",
                "    self.ds_Y = self.ds_Y[shuffler]\n",
                "    self.split = int(self.ds_X.shape[0]*split)\n",
                "    self.batch_size = batch_size\n",
                "    \n",
                "  def train_dataloader(self):\n",
                "    ds_X_train, ds_Y_train = self.ds_X[0:self.split], self.ds_Y[0:self.split]\n",
                "    return torch.utils.data.DataLoader(list(zip(ds_X_train, ds_Y_train)), batch_size=self.batch_size)\n",
                "\n",
                "  def val_dataloader(self):\n",
                "    ds_X_test, ds_Y_test = self.ds_X[self.split:], self.ds_Y[self.split:]\n",
                "    return torch.utils.data.DataLoader(list(zip(ds_X_test, ds_Y_test)), batch_size=self.batch_size)\n",
                "\n",
                "class ReverseDataModule(BaseDataModule):\n",
                "  def get_dataset(self, cnt=10000, seq_len=6):\n",
                "    ds = np.random.randint(0, 10, size=(cnt, seq_len))\n",
                "    return ds, ds[:, ::-1].ravel().reshape(cnt, seq_len)\n",
                "  \n",
                "# dataset idea from https://github.com/karpathy/minGPT/blob/master/play_math.ipynb\n",
                "class AdditionDataModule(BaseDataModule):\n",
                "  def get_dataset(self):\n",
                "    ret = []\n",
                "    for i in range(100):\n",
                "      for j in range(100):\n",
                "        s = i+j\n",
                "        ret.append([i//10, i%10, j//10, j%10, s//100, (s//10)%10, s%10])\n",
                "    ds = np.array(ret)\n",
                "    return ds[:, 0:6], np.copy(ds[:, 1:])    \n",
                "\n",
                "# this is the hardest to learn and requires 4 layers\n",
                "class ParityDataModule(BaseDataModule):\n",
                "  def get_dataset(self, seq_len=10):\n",
                "    ds_X, ds_Y = [], []\n",
                "    for i in range(2**seq_len):\n",
                "      x = [int(x) for x in list(bin(i)[2:].rjust(seq_len, '0'))]\n",
                "      ds_X.append(x)\n",
                "      ds_Y.append((np.cumsum(x)%2).tolist())\n",
                "    return np.array(ds_X), np.array(ds_Y)\n",
                "  \n",
                "class WikipediaDataModule(BaseDataModule):\n",
                "  def get_dataset(self, seq_len=50):\n",
                "    global enwik8\n",
                "    if 'enwik8' not in globals():\n",
                "      import requests\n",
                "      enwik8_zipped = requests.get(\"https://data.deepai.org/enwik8.zip\").content\n",
                "      from zipfile import ZipFile\n",
                "      import io\n",
                "      enwik8 = ZipFile(io.BytesIO(enwik8_zipped)).read('enwik8')\n",
                "    en = np.frombuffer(enwik8, dtype=np.uint8).astype(np.int)\n",
                "    en = en[0:-seq_len+1]\n",
                "    en[en>127] = 127\n",
                "    return en[0:-1].reshape(-1, seq_len), en[1:].reshape(-1, seq_len)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "323554ca",
            "metadata": {},
            "outputs": [],
            "source": [
                "def attention(queries, keys, values):\n",
                "  d = queries.shape[-1]\n",
                "  scores = torch.matmul(queries, keys.transpose(-2,-1))/math.sqrt(d)\n",
                "  attention_weights = F.softmax(scores, dim=-1)\n",
                "  return torch.matmul(attention_weights, values)\n",
                "\n",
                "class MultiHeadAttention(nn.Module):\n",
                "  def __init__(self, embed_dim, num_heads):\n",
                "    super(MultiHeadAttention, self).__init__()\n",
                "    self.embed_dim, self.num_heads = embed_dim, num_heads\n",
                "    assert embed_dim % num_heads == 0\n",
                "    self.projection_dim = embed_dim // num_heads\n",
                "    \n",
                "    self.W_q = nn.Linear(embed_dim, embed_dim)\n",
                "    self.W_k = nn.Linear(embed_dim, embed_dim)\n",
                "    self.W_v = nn.Linear(embed_dim, embed_dim)\n",
                "    self.W_o = nn.Linear(embed_dim, embed_dim)\n",
                "\n",
                "  def transpose(self, x):\n",
                "    x = x.reshape(x.shape[0], x.shape[1], self.num_heads, self.projection_dim)\n",
                "    return x.permute(0, 2, 1, 3)\n",
                "  \n",
                "  def transpose_output(self, x):\n",
                "    x = x.permute(0, 2, 1, 3)\n",
                "    return x.reshape(x.shape[0], x.shape[1], self.embed_dim)\n",
                "    \n",
                "  def forward(self, q, k, v):\n",
                "    q = self.transpose(self.W_q(q))\n",
                "    k = self.transpose(self.W_k(k))\n",
                "    v = self.transpose(self.W_v(v))\n",
                "    output = attention(q, k, v)\n",
                "    return self.W_o(self.transpose_output(output))\n",
                "  \n",
                "class TransformerBlock(nn.Module):\n",
                "  def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
                "    super(TransformerBlock, self).__init__()\n",
                "    self.att = MultiHeadAttention(embed_dim, num_heads)\n",
                "    self.ffn = nn.Sequential(\n",
                "      nn.Linear(embed_dim, ff_dim), nn.ReLU(), nn.Linear(ff_dim, embed_dim)\n",
                "    )\n",
                "    self.layernorm1 = nn.LayerNorm(embed_dim)\n",
                "    self.layernorm2 = nn.LayerNorm(embed_dim)\n",
                "    self.dropout = nn.Dropout(rate)\n",
                "    \n",
                "  def forward(self, x):\n",
                "    x = self.layernorm1(x + self.dropout(self.att(x, x, x)))\n",
                "    x = self.layernorm2(x + self.dropout(self.ffn(x)))\n",
                "    return x\n",
                "  \n",
                "class TokenAndPositionEmbedding(nn.Module):\n",
                "  def __init__(self, maxlen, vocab_size, embed_dim):\n",
                "    super(TokenAndPositionEmbedding, self).__init__()\n",
                "    self.token_emb = nn.Embedding(vocab_size, embed_dim)\n",
                "    self.pos_emb = nn.Embedding(maxlen, embed_dim)\n",
                "  def forward(self, x):\n",
                "    pos = torch.arange(0, x.size(1), dtype=torch.int32, device=x.device)\n",
                "    return self.token_emb(x) + self.pos_emb(pos).view(1, x.size(1), -1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "167e42e3",
            "metadata": {},
            "outputs": [],
            "source": [
                "class LittleTransformer(pl.LightningModule):\n",
                "  def __init__(self, seq_len=6, max_value=10, layer_count=2, embed_dim=128, num_heads=4, ff_dim=32):\n",
                "    super().__init__()\n",
                "    self.max_value = max_value\n",
                "    self.model = nn.Sequential(\n",
                "      TokenAndPositionEmbedding(seq_len, max_value, embed_dim),\n",
                "      *[TransformerBlock(embed_dim, num_heads, ff_dim) for x in range(layer_count)],\n",
                "      nn.Linear(embed_dim, max_value),\n",
                "      nn.LogSoftmax(dim=-1))\n",
                "    \n",
                "  def forward(self, x):\n",
                "    return self.model(x)\n",
                "  \n",
                "  def training_step(self, batch, batch_idx):\n",
                "    x, y = batch\n",
                "    output = self.model(x)\n",
                "    loss = F.nll_loss(output.view(-1, self.max_value), y.view(-1))\n",
                "    self.log(\"train_loss\", loss)\n",
                "    return loss\n",
                "  \n",
                "  def validation_step(self, val_batch, batch_idx):\n",
                "    x, y = val_batch\n",
                "    pred = self.model(x).argmax(dim=2)\n",
                "    val_accuracy = (pred == y).type(torch.float).mean()\n",
                "    self.log(\"val_accuracy\", val_accuracy, prog_bar=True)\n",
                "  \n",
                "  def configure_optimizers(self):\n",
                "    if self.device.type == 'cuda':\n",
                "      import apex\n",
                "      return apex.optimizers.FusedAdam(self.parameters(), lr=3e-4)\n",
                "    else:\n",
                "      return torch.optim.Adam(self.parameters(), lr=3e-4)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "id": "a2f48c98",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "GPU available: True (mps), used: True\n",
                        "TPU available: False, using: 0 TPU cores\n",
                        "IPU available: False, using: 0 IPUs\n",
                        "HPU available: False, using: 0 HPUs\n",
                        "\n",
                        "  | Name  | Type       | Params\n",
                        "-------------------------------------\n",
                        "0 | model | Sequential | 153 K \n",
                        "-------------------------------------\n",
                        "153 K     Trainable params\n",
                        "0         Non-trainable params\n",
                        "153 K     Total params\n",
                        "0.613     Total estimated model params size (MB)\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "7d0fa2931dd94be78b29a6869e65745c",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Sanity Checking: 0it [00:00, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/Users/alexandercamuto/Documents/GitHub/ezkl/.env/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 10 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
                        "  rank_zero_warn(\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "2f19ba5678e6452884faea1d5ad2d88f",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Training: 0it [00:00, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "model = LittleTransformer(seq_len=6)\n",
                "trainer = pl.Trainer(enable_progress_bar=True, max_epochs=5)\n",
                "data = AdditionDataModule(batch_size=64)\n",
                "#data = ReverseDataModule(cnt=1000, seq_len=20)\n",
                "#data = ParityDataModule(seq_len=14)\n",
                "trainer.fit(model, data)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "fa7d277e",
            "metadata": {},
            "source": [
                "## EZKL "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "6f339a28",
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "import os \n",
                "\n",
                "model_path = os.path.join('network.onnx')\n",
                "compiled_model_path = os.path.join('network.compiled')\n",
                "pk_path = os.path.join('test.pk')\n",
                "vk_path = os.path.join('test.vk')\n",
                "settings_path = os.path.join('settings.json')\n",
                "srs_path = os.path.join('kzg.srs')\n",
                "witness_path = os.path.join('witness.json')\n",
                "data_path = os.path.join('input.json')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "id": "27ce542b",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "torch.Size([1, 6])\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/var/folders/xm/20mc8dns1bd9qlh0q0_kvdz00000gn/T/ipykernel_35660/1190420391.py:3: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
                        "  scores = torch.matmul(queries, keys.transpose(-2,-1))/math.sqrt(d)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "================ Diagnostic Run torch.onnx.export version 2.0.1 ================\n",
                        "verbose: False, log level: Level.ERROR\n",
                        "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
                        "\n",
                        "{'input_data': [[0, 2, 3, 1, 0, 3]]}\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/Users/alexandercamuto/Documents/GitHub/ezkl/.env/lib/python3.9/site-packages/torch/onnx/utils.py:1636: UserWarning: The exported ONNX model failed ONNX shape inference.The model will not be executable by the ONNX Runtime.If this is unintended and you believe there is a bug,please report an issue at https://github.com/pytorch/pytorch/issues.Error reported by strict ONNX shape inference: [ShapeInferenceError] (op_type:ConstantOfShape, node name: /model/model.0/ConstantOfShape): input typestr: T1, has unsupported type: tensor(int32) (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/jit/serialization/export.cpp:1413.)\n",
                        "  _C._check_onnx_proto(proto)\n"
                    ]
                }
            ],
            "source": [
                "\n",
                "import json \n",
                "# After training, export to onnx (network.onnx) and create a data file (input.json)\n",
                "x = torch.tensor(data.train_dataloader().dataset[0][0])\n",
                "x = x.reshape([1, 6])\n",
                "\n",
                "print(x.shape)\n",
                "\n",
                "# Flips the neural net into inference mode\n",
                "model.eval()\n",
                "model.to('cpu')\n",
                "\n",
                "    # Export the model\n",
                "torch.onnx.export(model,               # model being run\n",
                "                      x,                   # model input (or a tuple for multiple inputs)\n",
                "                      model_path,            # where to save the model (can be a file or file-like object)\n",
                "                      export_params=True,        # store the trained parameter weights inside the model file\n",
                "                      opset_version=10,          # the ONNX version to export the model to\n",
                "                      do_constant_folding=True,  # whether to execute constant folding for optimization\n",
                "                      input_names = ['input'],   # the model's input names\n",
                "                      output_names = ['output'], # the model's output names\n",
                "                      dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
                "                                    'output' : {0 : 'batch_size'}})\n",
                "\n",
                "data_array = ((x).detach().numpy()).reshape([-1]).tolist()\n",
                "\n",
                "data_json = dict(input_data = [data_array])\n",
                "\n",
                "print(data_json)\n",
                "\n",
                "    # Serialize data into file:\n",
                "json.dump( data_json, open(data_path, 'w' ))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "2fe6d972",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "assuming the gather window is over a context variable\n",
                        "assuming the gather window is over a context variable\n",
                        "assuming the gather window is over a context variable\n",
                        "assuming the gather window is over a context variable\n",
                        "assuming the gather window is over a context variable\n",
                        "assuming the gather window is over a context variable\n",
                        "assuming the gather window is over a context variable\n",
                        "assuming the gather window is over a context variable\n",
                        "assuming the gather window is over a context variable\n",
                        "assuming the gather window is over a context variable\n",
                        "assuming the gather window is over a context variable\n",
                        "assuming the gather window is over a context variable\n",
                        "assuming the gather window is over a context variable\n",
                        "assuming the gather window is over a context variable\n",
                        "assuming the gather window is over a context variable\n",
                        "assuming the gather window is over a context variable\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "verified\n"
                    ]
                }
            ],
            "source": [
                "import ezkl \n",
                "\n",
                "!RUST_LOG=trace\n",
                "# TODO: Dictionary outputs\n",
                "res = ezkl.gen_settings(model_path, settings_path)\n",
                "assert res == True\n",
                "\n",
                "res = await ezkl.calibrate_settings(data_path, model_path, settings_path, \"resources\")\n",
                "assert res == True\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "id": "0990f5a8",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "assuming the gather window is over a context variable\n"
                    ]
                }
            ],
            "source": [
                "res = ezkl.compile_model(model_path, compiled_model_path, settings_path)\n",
                "assert res == True"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "id": "1b80dc01",
            "metadata": {},
            "outputs": [],
            "source": [
                "# srs path\n",
                "res = ezkl.get_srs(srs_path, settings_path)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "54cbde29",
            "metadata": {},
            "outputs": [],
            "source": [
                "# now generate the witness file \n",
                "witness_path = \"gan_witness.json\"\n",
                "\n",
                "res = ezkl.gen_witness(data_path, compiled_model_path, witness_path, settings_path = settings_path)\n",
                "assert os.path.isfile(witness_path)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "28760638",
            "metadata": {},
            "outputs": [],
            "source": [
                "res = ezkl.mock(witness_path, compiled_model_path, settings_path)\n",
                "assert res == True"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5e595112",
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "# HERE WE SETUP THE CIRCUIT PARAMS\n",
                "# WE GOT KEYS\n",
                "# WE GOT CIRCUIT PARAMETERS\n",
                "# EVERYTHING ANYONE HAS EVER NEEDED FOR ZK\n",
                "\n",
                "res = ezkl.setup(\n",
                "        compiled_model_path,\n",
                "        vk_path,\n",
                "        pk_path,\n",
                "        srs_path,\n",
                "        settings_path,\n",
                "    )\n",
                "\n",
                "assert res == True\n",
                "assert os.path.isfile(vk_path)\n",
                "assert os.path.isfile(pk_path)\n",
                "assert os.path.isfile(settings_path)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d37adaef",
            "metadata": {},
            "outputs": [],
            "source": [
                "# GENERATE A PROOF\n",
                "\n",
                "\n",
                "proof_path = os.path.join('test.pf')\n",
                "\n",
                "res = ezkl.prove(\n",
                "        witness_path,\n",
                "        compiled_model_path,\n",
                "        pk_path,\n",
                "        proof_path,\n",
                "        srs_path,\n",
                "        \"evm\",\n",
                "        \"single\",\n",
                "        settings_path,\n",
                "    )\n",
                "\n",
                "print(res)\n",
                "assert os.path.isfile(proof_path)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5b58acd5",
            "metadata": {},
            "outputs": [],
            "source": [
                "# VERIFY IT\n",
                "res = ezkl.verify(\n",
                "        proof_path,\n",
                "        settings_path,\n",
                "        vk_path,\n",
                "        srs_path,\n",
                "    )\n",
                "\n",
                "assert res == True\n",
                "print(\"verified\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.15"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
