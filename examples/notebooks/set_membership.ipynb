{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cf69bb3f-94e6-4dba-92cd-ce08df117d67",
   "metadata": {},
   "source": [
    "## Hash set membership demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95613ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if notebook is in colab\n",
    "try:\n",
    "    # install ezkl\n",
    "    import google.colab\n",
    "    import subprocess\n",
    "    import sys\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"ezkl\"])\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"onnx\"])\n",
    "\n",
    "# rely on local installation of ezkl if the notebook is not in colab\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "# here we create and (potentially train a model)\n",
    "\n",
    "# make sure you have the dependencies required here already installed\n",
    "from torch import nn\n",
    "import ezkl\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "\n",
    "        # this is a constant set\n",
    "        self.set = torch.nn.Parameter(torch.tensor([0.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        diff = (x - self.set)\n",
    "        membership_test = torch.prod(diff, dim=1)\n",
    "        return membership_test\n",
    "\n",
    "\n",
    "circuit = MyModel()\n",
    "\n",
    "# Train the model as you like here (skipped for brevity)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b37637c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join('network.onnx')\n",
    "compiled_model_path = os.path.join('network.compiled')\n",
    "pk_path = os.path.join('test.pk')\n",
    "vk_path = os.path.join('test.vk')\n",
    "settings_path = os.path.join('settings.json')\n",
    "srs_path = os.path.join('kzg.srs')\n",
    "witness_path = os.path.join('witness.json')\n",
    "data_path = os.path.join('input.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c833f08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1\n"
     ]
    }
   ],
   "source": [
    "# print pytorch version \n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82db373a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Diagnostic Run torch.onnx.export version 2.0.1 ================\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# After training, export to onnx (network.onnx) and create a data file (input.json)\n",
    "# hash(0) = 0x00000000, so this will be a member of the set\n",
    "x = 0.1*torch.zeros(1,*[1], requires_grad=True)\n",
    "\n",
    "# Flips the neural net into inference mode\n",
    "circuit.eval()\n",
    "\n",
    "    # Export the model\n",
    "torch.onnx.export(circuit,               # model being run\n",
    "                      x,                   # model input (or a tuple for multiple inputs)\n",
    "                      model_path,            # where to save the model (can be a file or file-like object)\n",
    "                      export_params=True,        # store the trained parameter weights inside the model file\n",
    "                      opset_version=14,          # the ONNX version to export the model to\n",
    "                      do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                      input_names = ['input'],   # the model's input names\n",
    "                      output_names = ['output'], # the model's output names\n",
    "                      dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
    "                                    'output' : {0 : 'batch_size'}})\n",
    "\n",
    "data_array = ((x).detach().numpy()).reshape([-1]).tolist()\n",
    "\n",
    "data = dict(input_data = [data_array])\n",
    "\n",
    "    # Serialize data into file:\n",
    "json.dump( data, open(data_path, 'w' ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5e374a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_args = ezkl.PyRunArgs()\n",
    "# \"hashed/private\" means that the output of the hashing is not visible to the verifier and is instead fed into the computational graph\n",
    "run_args.input_visibility = \"hashed/private\"\n",
    "# we set it to fix the set we want to check membership for\n",
    "run_args.param_visibility = \"public\"\n",
    "# the output is public -- set membership fails if it is not = 0\n",
    "run_args.output_visibility = \"public\"\n",
    "run_args.variables = [(\"batch_size\", 1)]\n",
    "# never rebase the scale\n",
    "run_args.scale_rebase_multiplier = 1000\n",
    "# logrows\n",
    "run_args.logrows = 11\n",
    "\n",
    "#  this creates the following sequence of ops:\n",
    "# 1. hash the input -> poseidon(x)\n",
    "# 2. compute the set difference -> poseidon(x) - set\n",
    "# 3. compute the product of the set difference -> prod(poseidon(x) - set)\n",
    "\n",
    "\n",
    "# TODO: Dictionary outputs\n",
    "res = ezkl.gen_settings(model_path, settings_path, py_run_args=run_args)\n",
    "assert res == True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3aa4f090",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = ezkl.compile_circuit(model_path, compiled_model_path, settings_path)\n",
    "assert res == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b74dcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# srs path\n",
    "res = ezkl.get_srs(srs_path, settings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18c8b7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now generate the witness file \n",
    "\n",
    "res = ezkl.gen_witness(data_path, compiled_model_path, witness_path)\n",
    "assert os.path.isfile(witness_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1c561a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: [Value { inner: Tensor { inner: [Value(Value { inner: Some(0x0000000000000000000000000000000000000000000000000000000000000000) })], dims: [1], scale: None, visibility: None }, dims: [1], scale: 1 }]\n",
      "inputs: [Value { inner: Tensor { inner: [Value(Value { inner: Some(0x0000000000000000000000000000000000000000000000000000000000000000) })], dims: [1], scale: None, visibility: None }, dims: [1], scale: 1 }]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# HERE WE SETUP THE CIRCUIT PARAMS\n",
    "# WE GOT KEYS\n",
    "# WE GOT CIRCUIT PARAMETERS\n",
    "# EVERYTHING ANYONE HAS EVER NEEDED FOR ZK\n",
    "\n",
    "\n",
    "\n",
    "res = ezkl.setup(\n",
    "        compiled_model_path,\n",
    "        vk_path,\n",
    "        pk_path,\n",
    "        srs_path,\n",
    "    )\n",
    "\n",
    "assert res == True\n",
    "assert os.path.isfile(vk_path)\n",
    "assert os.path.isfile(pk_path)\n",
    "assert os.path.isfile(settings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c384cbc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: [Value { inner: Tensor { inner: [Value(Value { inner: Some(0x0000000000000000000000000000000000000000000000000000000000000000) })], dims: [1], scale: None, visibility: None }, dims: [1], scale: 1 }]\n",
      "{'instances': [[[0, 0, 0, 0]], [[0, 0, 0, 0]]], 'proof': '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', 'transcript_type': 'EVM'}\n"
     ]
    }
   ],
   "source": [
    "# GENERATE A PROOF\n",
    "\n",
    "\n",
    "proof_path = os.path.join('test.pf')\n",
    "\n",
    "res = ezkl.prove(\n",
    "        witness_path,\n",
    "        compiled_model_path,\n",
    "        pk_path,\n",
    "        proof_path,\n",
    "        srs_path,\n",
    "        \"evm\",\n",
    "        \"single\",\n",
    "    )\n",
    "\n",
    "print(res)\n",
    "assert os.path.isfile(proof_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76f00d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verified\n"
     ]
    }
   ],
   "source": [
    "# VERIFY IT\n",
    "\n",
    "res = ezkl.verify(\n",
    "        proof_path,\n",
    "        settings_path,\n",
    "        vk_path,\n",
    "        srs_path,\n",
    "    )\n",
    "\n",
    "assert res == True\n",
    "print(\"verified\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
