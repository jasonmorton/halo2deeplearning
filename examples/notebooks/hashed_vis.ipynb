{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# hashed-ezkl\n",
                "\n",
                "Here's an example leveraging EZKL whereby the inputs to the model, and the model params themselves, are hashed inside a circuit.\n",
                "\n",
                "In this setup:\n",
                "- the hashes are publicly known to the prover and verifier\n",
                "- the hashes serve as \"public inputs\" (a.k.a instances) to the circuit\n",
                "\n",
                "We leave the outputs of the model as public as well (known to the  verifier and prover). \n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "First we import the necessary dependencies and set up logging to be as informative as possible. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from torch import nn\n",
                "import ezkl\n",
                "import os\n",
                "import json\n",
                "import logging\n",
                "\n",
                "# uncomment for more descriptive logging \n",
                "FORMAT = '%(levelname)s %(name)s %(asctime)-15s %(filename)s:%(lineno)d %(message)s'\n",
                "logging.basicConfig(format=FORMAT)\n",
                "logging.getLogger().setLevel(logging.INFO)\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now we define our model. It is a humble model with but a conv layer and a $ReLU$ non-linearity, but it is a model nonetheless"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "# Defines the model\n",
                "# we got convs, we got relu, \n",
                "# What else could one want ????\n",
                "\n",
                "class MyModel(nn.Module):\n",
                "    def __init__(self):\n",
                "        super(MyModel, self).__init__()\n",
                "\n",
                "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=1, kernel_size=5, stride=4)\n",
                "        self.relu = nn.ReLU()\n",
                "\n",
                "    def forward(self, x):\n",
                "        x = self.conv1(x)\n",
                "        x = self.relu(x)\n",
                "\n",
                "        return x\n",
                "\n",
                "\n",
                "circuit = MyModel()\n",
                "\n",
                "# this is where you'd train your model\n",
                "\n",
                "\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We omit training for purposes of this demonstration. We've marked where training would happen in the cell above. \n",
                "Now we export the model to onnx and create a corresponding (randomly generated) input file.\n",
                "\n",
                "You can replace the random `x` with real data if you so wish. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "================ Diagnostic Run torch.onnx.export version 2.0.1 ================\n",
                        "verbose: False, log level: Level.ERROR\n",
                        "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "x = torch.rand(1,*[3, 8, 8], requires_grad=True)\n",
                "\n",
                "# Flips the neural net into inference mode\n",
                "circuit.eval()\n",
                "\n",
                "    # Export the model\n",
                "torch.onnx.export(circuit,               # model being run\n",
                "                      x,                   # model input (or a tuple for multiple inputs)\n",
                "                      \"network.onnx\",            # where to save the model (can be a file or file-like object)\n",
                "                      export_params=True,        # store the trained parameter weights inside the model file\n",
                "                      opset_version=10,          # the ONNX version to export the model to\n",
                "                      do_constant_folding=True,  # whether to execute constant folding for optimization\n",
                "                      input_names = ['input'],   # the model's input names\n",
                "                      output_names = ['output'], # the model's output names\n",
                "                      dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
                "                                    'output' : {0 : 'batch_size'}})\n",
                "\n",
                "data_array = ((x).detach().numpy()).reshape([-1]).tolist()\n",
                "\n",
                "data = dict(input_data = [data_array])\n",
                "\n",
                "    # Serialize data into file:\n",
                "json.dump( data, open(\"input.json\", 'w' ))\n",
                "\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "This is where the magic happens. We define our `PyRunArgs` objects which contains the visibility parameters for out model. \n",
                "- `input_visibility` defines the visibility of the model inputs\n",
                "- `param_visibility` defines the visibility of the model weights and constants and parameters \n",
                "- `output_visibility` defines the visibility of the model outputs\n",
                "\n",
                "There are currently 4 visibility settings:\n",
                "- `public`: known to both the verifier and prover (a subtle nuance is that this may not be the case for model parameters but until we have more rigorous theoretical results we don't want to make strong claims as to this). \n",
                "- `private`: known only to the prover\n",
                "- `hashed`: the hash pre-image is known to the prover, the prover and verifier know the hash. The prover proves that the they know the pre-image to the hash. \n",
                "- `encrypted`: the non-encrypted element and the secret key used for decryption are known to the prover. The prover and the verifier know the encrypted element, the public key used to encrypt, and the hash of the decryption hey. The prover proves that they know the pre-image of the hashed decryption key and that this key can in fact decrypt the encrypted message.\n",
                "\n",
                "Here we create the following setup:\n",
                "- `input_visibility`: \"hashed\"\n",
                "- `param_visibility`: \"hashed\"\n",
                "- `output_visibility`: public\n",
                "\n",
                "We encourage you to play around with other setups :) \n",
                "\n",
                "Shoutouts: \n",
                "\n",
                "- [summa-solvency](https://github.com/summa-dev/summa-solvency) for their help with the poseidon hashing chip. \n",
                "- [timeofey](https://github.com/timoftime) for providing inspiration in our developement of the el-gamal encryption circuit in Halo2. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import ezkl\n",
                "\n",
                "model_path = os.path.join('network.onnx')\n",
                "compiled_model_path = os.path.join('network.compiled')\n",
                "pk_path = os.path.join('test.pk')\n",
                "vk_path = os.path.join('test.vk')\n",
                "settings_path = os.path.join('settings.json')\n",
                "srs_path = os.path.join('kzg.srs')\n",
                "data_path = os.path.join('input.json')\n",
                "\n",
                "run_args = ezkl.PyRunArgs()\n",
                "run_args.input_visibility = \"hashed\"\n",
                "run_args.param_visibility = \"hashed\"\n",
                "run_args.output_visibility = \"public\"\n",
                "\n",
                "\n",
                "\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now we generate a settings file. This file basically instantiates a bunch of parameters that determine their circuit shape, size etc... Because of the way we represent nonlinearities in the circuit (using Halo2's [lookup tables](https://zcash.github.io/halo2/design/proving-system/lookup.html)), it is often best to _calibrate_ this settings file as some data can fall out of range of these lookups.\n",
                "\n",
                "You can pass a dataset for calibration that will be representative of real inputs you might find if and when you deploy the prover. Here we create a dummy calibration dataset for demonstration purposes. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO ezkl.graph.model 2023-07-21 17:15:24,920 model.rs:421 set batch size to 1\n",
                        "INFO ezkl.graph.model 2023-07-21 17:15:24,923 model.rs:746 calculating num of constraints using dummy model layout...\n",
                        "INFO ezkl.graph.model 2023-07-21 17:15:24,924 model.rs:246 \u001b[34mmodel generates\u001b[0m \u001b[34m78\u001b[0m \u001b[34mconstraints (excluding modules)\u001b[0m\n"
                    ]
                }
            ],
            "source": [
                "!RUST_LOG=trace\n",
                "# TODO: Dictionary outputs\n",
                "res = ezkl.gen_settings(model_path, settings_path, py_run_args=run_args)\n",
                "assert res == True"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "ename": "TypeError",
                    "evalue": "cat() received an invalid combination of arguments - got (Tensor, Tensor), but expected one of:\n * (tuple of Tensors tensors, int dim, *, Tensor out)\n * (tuple of Tensors tensors, name dim, *, Tensor out)\n",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[49], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# generate a bunch of dummy calibration data\u001b[39;00m\n\u001b[1;32m      2\u001b[0m cal_data \u001b[39m=\u001b[39m {\n\u001b[0;32m----> 3\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39minput_data\u001b[39m\u001b[39m\"\u001b[39m: [torch\u001b[39m.\u001b[39;49mcat(x, torch\u001b[39m.\u001b[39;49mrand(\u001b[39m10\u001b[39;49m, \u001b[39m*\u001b[39;49m[\u001b[39m3\u001b[39;49m, \u001b[39m8\u001b[39;49m, \u001b[39m8\u001b[39;49m]))\u001b[39m.\u001b[39mflatten()\u001b[39m.\u001b[39mtolist()],\n\u001b[1;32m      4\u001b[0m }\n\u001b[1;32m      6\u001b[0m cal_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39mval_data.json\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[39m# save as json file\u001b[39;00m\n",
                        "\u001b[0;31mTypeError\u001b[0m: cat() received an invalid combination of arguments - got (Tensor, Tensor), but expected one of:\n * (tuple of Tensors tensors, int dim, *, Tensor out)\n * (tuple of Tensors tensors, name dim, *, Tensor out)\n"
                    ]
                }
            ],
            "source": [
                "# generate a bunch of dummy calibration data\n",
                "cal_data = {\n",
                "    \"input_data\": [torch.cat((x, torch.rand(10, *[3, 8, 8]))).flatten().tolist()],\n",
                "}\n",
                "\n",
                "cal_path = os.path.join('val_data.json')\n",
                "# save as json file\n",
                "with open(cal_path, \"w\") as f:\n",
                "    json.dump(cal_data, f)\n",
                "\n",
                "res = await ezkl.calibrate_settings(cal_path, model_path, settings_path, \"resources\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "res = ezkl.compile_model(model_path, compiled_model_path, settings_path)\n",
                "assert res == True"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "As we use Halo2 with KZG-commitments we need an SRS string from (preferably) a multi-party trusted setup ceremony. For an overview of the procedures for such a ceremony check out [this page](https://blog.ethereum.org/2023/01/16/announcing-kzg-ceremony). The `get_srs` command retrieves a correctly sized SRS given the calibrated settings file from [here](https://github.com/han0110/halo2-kzg-srs). \n",
                "\n",
                "These SRS were generated with [this](https://github.com/privacy-scaling-explorations/perpetualpowersoftau) ceremony. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 37,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO ezkl.execute 2023-07-21 17:15:30,021 execute.rs:502 SRS downloaded\n"
                    ]
                }
            ],
            "source": [
                "res = ezkl.get_srs(srs_path, settings_path)\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We now need to generate the (partial) circuit witness. These are the model outputs (and any hashes) that are generated when feeding the previously generated `input.json` through the circuit / model. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!export RUST_BACKTRACE=1\n",
                "\n",
                "witness_path = \"witness.json\"\n",
                "\n",
                "res = ezkl.gen_witness(data_path, compiled_model_path, witness_path, settings_path = settings_path)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "As a sanity check you can \"mock prove\" (i.e check that all the constraints of the circuit match without generate a full proof). "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 47,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO ezkl.graph.model 2023-07-21 17:16:10,233 model.rs:421 set batch size to 1\n",
                        "INFO ezkl.graph 2023-07-21 17:16:10,234 mod.rs:560 public inputs lengths: [1]\n",
                        "INFO ezkl.execute 2023-07-21 17:16:10,235 execute.rs:777 Mock proof\n",
                        "INFO ezkl.graph.model 2023-07-21 17:16:10,235 model.rs:572 configuring model\n",
                        "INFO ezkl.graph.model 2023-07-21 17:16:10,643 model.rs:604 model layout...\n",
                        "INFO ezkl.graph.model 2023-07-21 17:16:10,709 model.rs:666 computing...\n",
                        "INFO ezkl.graph.model 2023-07-21 17:16:10,710 model.rs:666 computing...\n"
                    ]
                }
            ],
            "source": [
                "\n",
                "\n",
                "res = ezkl.mock(witness_path, compiled_model_path, settings_path)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Here we setup verifying and proving keys for the circuit. As the name suggests the proving key is needed for ... proving and the verifying key is needed for ... verifying. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 40,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO ezkl.graph.model 2023-07-21 17:15:30,929 model.rs:421 set batch size to 1\n",
                        "INFO ezkl.pfsys.srs 2023-07-21 17:15:30,930 srs.rs:23 loading srs from \"kzg.srs\"\n",
                        "INFO ezkl.execute 2023-07-21 17:15:30,935 execute.rs:1634 downsizing params to 15 logrows\n",
                        "INFO ezkl.graph.model 2023-07-21 17:15:30,935 model.rs:572 configuring model\n",
                        "INFO ezkl.graph.model 2023-07-21 17:15:30,961 model.rs:604 model layout...\n",
                        "INFO ezkl.graph.model 2023-07-21 17:15:30,978 model.rs:666 computing...\n",
                        "INFO ezkl.graph.model 2023-07-21 17:15:30,979 model.rs:666 computing...\n",
                        "INFO ezkl.pfsys 2023-07-21 17:15:32,265 mod.rs:369 VK took 1.330\n",
                        "INFO ezkl.graph.model 2023-07-21 17:15:32,266 model.rs:572 configuring model\n",
                        "INFO ezkl.graph.model 2023-07-21 17:15:32,291 model.rs:604 model layout...\n",
                        "INFO ezkl.graph.model 2023-07-21 17:15:32,307 model.rs:666 computing...\n",
                        "INFO ezkl.graph.model 2023-07-21 17:15:32,308 model.rs:666 computing...\n",
                        "INFO ezkl.pfsys 2023-07-21 17:15:33,164 mod.rs:375 PK took 0.898\n",
                        "INFO ezkl.pfsys 2023-07-21 17:15:33,165 mod.rs:556 saving verification key 💾\n",
                        "INFO ezkl.pfsys 2023-07-21 17:15:33,166 mod.rs:539 saving proving key 💾\n"
                    ]
                }
            ],
            "source": [
                "# HERE WE SETUP THE CIRCUIT PARAMS\n",
                "# WE GOT KEYS\n",
                "# WE GOT CIRCUIT PARAMETERS\n",
                "# EVERYTHING ANYONE HAS EVER NEEDED FOR ZK\n",
                "res = ezkl.setup(\n",
                "        compiled_model_path,\n",
                "        vk_path,\n",
                "        pk_path,\n",
                "        srs_path,\n",
                "        settings_path,\n",
                "    )\n",
                "\n",
                "assert res == True\n",
                "assert os.path.isfile(vk_path)\n",
                "assert os.path.isfile(pk_path)\n",
                "assert os.path.isfile(settings_path)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now we generate a full proof. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 41,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO ezkl.graph.model 2023-07-21 17:15:33,383 model.rs:421 set batch size to 1\n",
                        "INFO ezkl.graph 2023-07-21 17:15:33,384 mod.rs:560 public inputs lengths: [1]\n",
                        "INFO ezkl.pfsys.srs 2023-07-21 17:15:33,385 srs.rs:23 loading srs from \"kzg.srs\"\n",
                        "INFO ezkl.execute 2023-07-21 17:15:33,389 execute.rs:1634 downsizing params to 15 logrows\n",
                        "INFO ezkl.pfsys 2023-07-21 17:15:33,390 mod.rs:519 loading proving key from \"test.pk\"\n",
                        "INFO ezkl.graph.model 2023-07-21 17:15:33,390 model.rs:572 configuring model\n",
                        "INFO ezkl.pfsys 2023-07-21 17:15:33,635 mod.rs:429 proof started...\n",
                        "INFO ezkl.graph.model 2023-07-21 17:15:33,635 model.rs:572 configuring model\n",
                        "INFO ezkl.graph.model 2023-07-21 17:15:34,041 model.rs:604 model layout...\n",
                        "INFO ezkl.graph.model 2023-07-21 17:15:34,056 model.rs:666 computing...\n",
                        "INFO ezkl.graph.model 2023-07-21 17:15:34,057 model.rs:666 computing...\n",
                        "INFO ezkl.execute 2023-07-21 17:15:36,555 execute.rs:1177 proof took 2.920\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "{'instances': [[[0, 0, 0, 0]], [[14274608303896394872, 3702323036926418149, 7698009275440366899, 3432088659181290681], [0, 0, 0, 0]]], 'proof': '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', 'transcript_type': 'EVM'}\n"
                    ]
                }
            ],
            "source": [
                "# GENERATE A PROOF\n",
                "\n",
                "proof_path = os.path.join('test.pf')\n",
                "\n",
                "res = ezkl.prove(\n",
                "        witness_path,\n",
                "        compiled_model_path,\n",
                "        pk_path,\n",
                "        proof_path,\n",
                "        srs_path,\n",
                "        \"evm\",\n",
                "        \"single\",\n",
                "        settings_path,\n",
                "    )\n",
                "\n",
                "print(res)\n",
                "assert os.path.isfile(proof_path)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "And verify it as a sanity check. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 42,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO ezkl.pfsys.srs 2023-07-21 17:15:36,571 srs.rs:23 loading srs from \"kzg.srs\"\n",
                        "INFO ezkl.execute 2023-07-21 17:15:36,576 execute.rs:1634 downsizing params to 15 logrows\n",
                        "INFO ezkl.pfsys 2023-07-21 17:15:36,578 mod.rs:498 loading verification key from \"test.vk\"\n",
                        "INFO ezkl.graph.model 2023-07-21 17:15:36,579 model.rs:572 configuring model\n",
                        "INFO ezkl.execute 2023-07-21 17:15:36,594 execute.rs:1593 verify took 0.8\n",
                        "INFO ezkl.execute 2023-07-21 17:15:36,594 execute.rs:1598 verified: true\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "verified\n"
                    ]
                }
            ],
            "source": [
                "# VERIFY IT\n",
                "\n",
                "res = ezkl.verify(\n",
                "        proof_path,\n",
                "        settings_path,\n",
                "        vk_path,\n",
                "        srs_path,\n",
                "    )\n",
                "\n",
                "assert res == True\n",
                "print(\"verified\")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We can now create an EVM / `.sol` verifier that can be deployed on chain to verify submitted proofs using a view function."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 43,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO ezkl.execute 2023-07-21 17:15:36,600 execute.rs:80 checking solc installation..\n",
                        "INFO ezkl.pfsys.srs 2023-07-21 17:15:36,601 srs.rs:23 loading srs from \"kzg.srs\"\n",
                        "INFO ezkl.execute 2023-07-21 17:15:36,604 execute.rs:1634 downsizing params to 15 logrows\n",
                        "INFO ezkl.pfsys 2023-07-21 17:15:36,605 mod.rs:498 loading verification key from \"test.vk\"\n",
                        "INFO ezkl.graph.model 2023-07-21 17:15:36,605 model.rs:572 configuring model\n"
                    ]
                }
            ],
            "source": [
                "\n",
                "abi_path = 'test.abi'\n",
                "sol_code_path = 'test.sol'\n",
                "\n",
                "res = ezkl.create_evm_verifier(\n",
                "        vk_path,\n",
                "        srs_path,\n",
                "        settings_path,\n",
                "        sol_code_path,\n",
                "        abi_path,\n",
                "    )\n",
                "assert res == True\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Verify on the evm"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 44,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO ezkl.execute 2023-07-21 17:15:36,914 execute.rs:80 checking solc installation..\n"
                    ]
                },
                {
                    "ename": "RuntimeError",
                    "evalue": "Failed to run deploy_evm: error sending request for url (http://127.0.0.1:3030/): error trying to connect: tcp connect error: Connection refused (os error 61)",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[44], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjson\u001b[39;00m\n\u001b[1;32m      6\u001b[0m address_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m\"\u001b[39m\u001b[39maddress.json\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m res \u001b[39m=\u001b[39m ezkl\u001b[39m.\u001b[39;49mdeploy_evm(\n\u001b[1;32m      9\u001b[0m     address_path,\n\u001b[1;32m     10\u001b[0m     sol_code_path,\n\u001b[1;32m     11\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mhttp://127.0.0.1:3030\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[39massert\u001b[39;00m res \u001b[39m==\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(address_path, \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m file:\n",
                        "\u001b[0;31mRuntimeError\u001b[0m: Failed to run deploy_evm: error sending request for url (http://127.0.0.1:3030/): error trying to connect: tcp connect error: Connection refused (os error 61)"
                    ]
                }
            ],
            "source": [
                "# Make sure anvil is running locally first\n",
                "# run with $ anvil -p 3030\n",
                "# we use the default anvil node here\n",
                "import json\n",
                "\n",
                "address_path = os.path.join(\"address.json\")\n",
                "\n",
                "res = ezkl.deploy_evm(\n",
                "    address_path,\n",
                "    sol_code_path,\n",
                "    'http://127.0.0.1:3030'\n",
                ")\n",
                "\n",
                "assert res == True\n",
                "\n",
                "with open(address_path, 'r') as file:\n",
                "    addr = file.read().rstrip()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# make sure anvil is running locally\n",
                "# $ anvil -p 3030\n",
                "\n",
                "res = ezkl.verify_evm(\n",
                "    proof_path,\n",
                "    addr,\n",
                "    \"http://127.0.0.1:3030\"\n",
                ")\n",
                "assert res == True"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "ezkl",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.15"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
